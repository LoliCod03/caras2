<!doctype html>
<html lang="es">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>IA Rostros - Fixed</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body { background-color: #121212; color: white; font-family: 'Segoe UI', sans-serif; }
        .contenedor-camara { width: 350px; height: 350px; margin: 20px auto; border: 4px solid #00d1b2; border-radius: 15px; overflow: hidden; }
        #resultado { font-size: 2rem; color: #00d1b2; font-weight: bold; }
    </style>
</head>
<body>

<div class="container text-center mt-5">
    <h2>Reconocedor Facial</h2>
    <div id="status" class="alert alert-info">Cargando...</div>
    <div class="contenedor-camara">
        <canvas id="canvas" width="400" height="400" style="width: 100%; height: 100%;"></canvas>
    </div>
    <div id="resultado">Esperando IA...</div>
    <video id="video" playsinline autoplay style="width: 1px; visibility: hidden;"></video>
    <canvas id="othercanvas" width="150" height="150" style="display: none"></canvas>
</div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.22.0/dist/tf.min.js"></script>

<script>
    var video = document.getElementById("video");
    var canvas = document.getElementById("canvas");
    var ctx = canvas.getContext("2d");
    var modelo = null;

    const PERSONAS = ["Daniela", "Fajardo", "Gabriel", "Idney", "Jesús", "Kevin", "Victor"];

    async function cargarModelo() {
        try {
            // 1. Obtener el JSON
            const response = await fetch('./model.json');
            const modelArtifacts = await response.json();

            // 2. PARCHE AGRESIVO: Buscamos el InputLayer donde sea que esté
            if (modelArtifacts.modelTopology && modelArtifacts.modelTopology.model_config) {
                const modelConfig = modelArtifacts.modelTopology.model_config;
                
                // Keras 3 a veces pone las capas en config.layers o config.layers_configs
                let layers = modelConfig.config.layers || modelConfig.config.layers_configs;

                if (layers) {
                    layers.forEach(layer => {
                        // Si es la capa de entrada o la primera capa funcional
                        if (layer.class_name === "InputLayer" || (layer.config && !layer.config.batch_input_shape)) {
                            if (!layer.config) layer.config = {};
                            // Inyectamos el tamaño que falta
                            layer.config.batch_input_shape = [null, 150, 150, 3];
                        }
                    });
                }
            }

            // 3. Carga usando la firma de un solo argumento (para evitar el error de passthrough.js)
            // Creamos un objeto consolidado
            const handler = tf.io.fromMemory(
                modelArtifacts.modelTopology,
                modelArtifacts.weightsManifest,
                modelArtifacts.weightData // Esto puede ser nulo al cargar de URL
            );

            // Intentamos la carga directa desde la URL para que gestione los .bin automáticamente
            // pero con el JSON ya parcheado en una URL temporal
            const blob = new Blob([JSON.stringify(modelArtifacts)], {type : 'application/json'});
            const modelUrl = URL.createObjectURL(blob);
            
            modelo = await tf.loadLayersModel(modelUrl);

            document.getElementById("status").innerText = "¡IA Cargada Exitosamente!";
            document.getElementById("status").className = "alert alert-success";
            predecir();
        } catch (error) {
            console.error("Error crítico:", error);
            document.getElementById("status").innerText = "Error de compatibilidad. Revisa consola.";
            document.getElementById("status").className = "alert alert-danger";
        }
    }

    // --- Funciones de cámara (Sin cambios) ---
    function mostrarCamara() {
        navigator.mediaDevices.getUserMedia({video: {facingMode: "user", width: 400, height: 400}})
            .then(function(stream) { video.srcObject = stream; procesarCamara(); })
            .catch(function(err) { console.error(err); });
    }

    function procesarCamara() {
        ctx.drawImage(video, 0, 0, 400, 400, 0, 0, 400, 400);
        setTimeout(procesarCamara, 20);
    }

    async function predecir() {
        if (modelo != null) {
            const tempCanvas = document.getElementById("othercanvas");
            const tempCtx = tempCanvas.getContext("2d");
            tempCtx.drawImage(canvas, 0, 0, 400, 400, 0, 0, 150, 150);

            const prediccion = tf.tidy(() => {
                const tensor = tf.browser.fromPixels(tempCanvas)
                                 .toFloat().div(255.0).expandDims(0);
                return modelo.predict(tensor).dataSync();
            });

            let maxIndex = prediccion.indexOf(Math.max(...prediccion));
            if (prediccion[maxIndex] > 0.6) {
                document.getElementById("resultado").innerText = PERSONAS[maxIndex];
            } else {
                document.getElementById("resultado").innerText = "Escaneando...";
            }
        }
        setTimeout(predecir, 450);
    }

    window.onload = () => { mostrarCamara(); cargarModelo(); };
</script>
</body>
</html>
